{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from string import punctuation\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import scipy.stats as sts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Составьте самостоятельно как минимум две коллекции текстов разных стилей (например, коллекция текстов в публицистическом стиле и коллекция текстов в научном стиле). Коллекции текстов должны быть достаточно большие (порядка 5000 токенов). Посчитайте количество токенов и типов в каждой коллекции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция read_file считывает текстовый файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    f = open(file)\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция tokenize выделяет токены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    exclude = set(punctuation + '0123456789\\n'+u'–—'+u'«»')\n",
    "    merged_text = ''.join(ch for ch in text if ch not in exclude)\n",
    "    tokens = WhitespaceTokenizer().tokenize(merged_text.lower())\n",
    "    for i in tokens[:10]: \n",
    "        print(i)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция print_numbers подсчитывает количество токенов и типов в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_numbers(tokens):\n",
    "    print('Число токенов:', len(tokens))\n",
    "    types = nltk.FreqDist(tokens)\n",
    "    print('Число типов:', len(types))\n",
    "    print(types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для анализа были выбраны три текста: \"Преступление и наказание\" Ф.М. Достоевского (художественный стиль), Налоговый кодекс РФ (официально-деловой стиль) и кандидатская диссертация К.Р. Абаноковой на тему \"Изменение структуры домохозяйства как стратегия преодоления макроэкономического шока\" (научный стиль).\n",
    "\n",
    "Считаем тексты из файлов и подсчитаем количество токенов и типов в каждом из них. \n",
    "\n",
    "Художественный стиль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в\n",
      "начале\n",
      "июля\n",
      "в\n",
      "чрезвычайно\n",
      "жаркое\n",
      "время\n",
      "под\n",
      "вечер\n",
      "один\n"
     ]
    }
   ],
   "source": [
    "text_art = read_file('dostoevsky.txt')\n",
    "tokens_art = tokenize(text_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число токенов: 42088\n",
      "Число типов: 10332\n",
      "<FreqDist with 10332 samples and 42088 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print_numbers(tokens_art)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Научный стиль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "введение\n",
      "актуальность\n",
      "за\n",
      "последние\n",
      "два\n",
      "десятка\n",
      "лет\n",
      "российские\n",
      "домохозяйства\n",
      "испытали\n"
     ]
    }
   ],
   "source": [
    "text_sci = read_file('science.txt')\n",
    "tokens_sci = tokenize(text_sci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число токенов: 6070\n",
      "Число типов: 1999\n",
      "<FreqDist with 1999 samples and 6070 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print_numbers(tokens_sci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Официально-деловой стиль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "часть\n",
      "первая\n",
      "принята\n",
      "государственной\n",
      "думой\n",
      "июля\n",
      "года\n",
      "одобрена\n",
      "советом\n",
      "федерации\n"
     ]
    }
   ],
   "source": [
    "text_ofi = read_file('taxes_law.txt')\n",
    "tokens_ofi = tokenize(text_ofi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число токенов: 28224\n",
      "Число типов: 3649\n",
      "<FreqDist with 3649 samples and 28224 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print_numbers(tokens_ofi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Используя любой морфологический процессор, который вам нравится (pymorphy2, mystem), определите к какой части речи относятся слова из каждой коллекции текстов. При помощи nltk.FreqDist() составьте частотные словари: часть речи – количество слов, к ней относящихся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция pos_freq фильтрует стоп-слова, а также определяет части речи, к которым они относятся, при этом возвращая FreqDist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "\n",
    "def pos_freq(tokens):\n",
    "    filtered_text = [] # список для хранения отфильтрованного текста\n",
    "    pos = [] # список частей речи\n",
    "    for word in tokens:\n",
    "        if not word in stopwords.words('russian'): \n",
    "            filtered_text.append(word)\n",
    "            pos.append(morph.parse(word)[0].tag.POS)   \n",
    "    for i in range(20):\n",
    "        print(filtered_text[i] + ':' + pos[i])\n",
    "    return nltk.FreqDist(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "начале:NOUN\n",
      "июля:NOUN\n",
      "чрезвычайно:ADVB\n",
      "жаркое:NOUN\n",
      "время:NOUN\n",
      "вечер:NOUN\n",
      "молодой:NOUN\n",
      "человек:NOUN\n",
      "вышел:VERB\n",
      "своей:ADJF\n",
      "каморки:NOUN\n",
      "которую:ADJF\n",
      "нанимал:VERB\n",
      "жильцов:NOUN\n",
      "переулке:NOUN\n",
      "улицу:NOUN\n",
      "медленно:ADVB\n",
      "нерешимости:NOUN\n",
      "отправился:VERB\n",
      "мосту:NOUN\n"
     ]
    }
   ],
   "source": [
    "POS_freq_art = pos_freq(tokens_art)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение слов по частям речи в тексте художественного стиля:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'ADJF': 3487,\n",
       "          'ADJS': 519,\n",
       "          'ADVB': 2047,\n",
       "          'COMP': 145,\n",
       "          'CONJ': 401,\n",
       "          'GRND': 467,\n",
       "          'INFN': 1000,\n",
       "          'INTJ': 71,\n",
       "          'NOUN': 8535,\n",
       "          'NPRO': 284,\n",
       "          'NUMR': 259,\n",
       "          'PRCL': 436,\n",
       "          'PRED': 34,\n",
       "          'PREP': 133,\n",
       "          'PRTF': 302,\n",
       "          'PRTS': 254,\n",
       "          'VERB': 5072})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_freq_art"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Научный стиль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "введение:NOUN\n",
      "актуальность:NOUN\n",
      "последние:ADJF\n",
      "десятка:NOUN\n",
      "лет:NOUN\n",
      "российские:ADJF\n",
      "домохозяйства:NOUN\n",
      "испытали:VERB\n",
      "несколько:ADVB\n",
      "экономических:ADJF\n",
      "шоков:ADJS\n",
      "повлекших:PRTF\n",
      "собой:NPRO\n",
      "части:NOUN\n",
      "снижение:NOUN\n",
      "благосостояния:NOUN\n",
      "кризис:NOUN\n",
      "года:NOUN\n",
      "привел:VERB\n",
      "обесцениванию:NOUN\n"
     ]
    }
   ],
   "source": [
    "POS_freq_sci = pos_freq(tokens_sci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'ADJF': 932,\n",
       "          'ADJS': 35,\n",
       "          'ADVB': 71,\n",
       "          'COMP': 2,\n",
       "          'CONJ': 62,\n",
       "          'GRND': 24,\n",
       "          'INFN': 132,\n",
       "          'NOUN': 2759,\n",
       "          'NPRO': 8,\n",
       "          'NUMR': 10,\n",
       "          'PRCL': 10,\n",
       "          'PREP': 35,\n",
       "          'PRTF': 147,\n",
       "          'PRTS': 50,\n",
       "          'VERB': 379})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_freq_sci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Официально-деловой стиль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "часть:NOUN\n",
      "первая:ADJF\n",
      "принята:PRTS\n",
      "государственной:ADJF\n",
      "думой:NOUN\n",
      "июля:NOUN\n",
      "года:NOUN\n",
      "одобрена:PRTS\n",
      "советом:NOUN\n",
      "федерации:NOUN\n",
      "июля:NOUN\n",
      "года:NOUN\n",
      "раздел:NOUN\n",
      "общие:ADJF\n",
      "положения:NOUN\n",
      "глава:NOUN\n",
      "законодательство:NOUN\n",
      "налогах:NOUN\n",
      "сборах:NOUN\n",
      "иные:ADJF\n"
     ]
    }
   ],
   "source": [
    "POS_freq_ofi = pos_freq(tokens_ofi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'ADJF': 5672,\n",
       "          'ADJS': 52,\n",
       "          'ADVB': 239,\n",
       "          'CONJ': 166,\n",
       "          'GRND': 14,\n",
       "          'INFN': 272,\n",
       "          'NOUN': 13477,\n",
       "          'NPRO': 31,\n",
       "          'NUMR': 60,\n",
       "          'PRCL': 17,\n",
       "          'PRED': 32,\n",
       "          'PREP': 38,\n",
       "          'PRTF': 833,\n",
       "          'PRTS': 238,\n",
       "          'VERB': 883})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_freq_ofi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Посчитайте коэффициент корреляции Спирмена для полученных на предыдущем шаге частот частей речи. На основании полученного значения, сделайте вывод: подтверждается ли гипотеза,сформулированная в задании?  Если вы рассматривали больше двух стилей, можно ли утверждать, что один стиль больше похож на второй, чем на третий?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы подсчитать корреляцию Спирмена, необходимо сначала составить список всех частей речи, которые встретились в трех текстах, а затем для каждого текста каждой части речи сопоставить число слов, принадлежащих этой части речи и входящих к текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# записываем все возможные части речи в один список\n",
    "a = list(POS_freq_sci.keys())\n",
    "a.extend(list(POS_freq_ofi.keys()))\n",
    "a.extend(list(POS_freq_art.keys()))\n",
    "a = set(a)\n",
    "a = list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# списки для хранения векторов чисел, соответствующих частям речи списка a\n",
    "art = []\n",
    "sci = []\n",
    "ofi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in a:\n",
    "    art.append(POS_freq_art[k])\n",
    "    sci.append(POS_freq_sci[k])\n",
    "    ofi.append(POS_freq_ofi[k])\n",
    "\n",
    "# теперь в списках art, sci, ofi лежат упорядоченные значения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Подсчитаем все возможные парные корреляции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.68669540804024132, pvalue=0.0023287175307992749)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.spearmanr(art, ofi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.8029479546287005, pvalue=0.00010423561745532498)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.spearmanr(art, sci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.9281333785094753, pvalue=7.8977964188378654e-08)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.spearmanr(sci, ofi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все p-value оказались достаточно малы (меньше 0.01), а это значит, что на уровне значимости 0.01 можно отвергнуть основную гипотезу, которая заключается в том, что корреляция равна 0.\n",
    "\n",
    "Можно наблюдать, что наиболее сильно коррелируют тексты научного и официального стиля (spearmanr = 0.93), в то время как каждый из них коррелирует с текстом художественного стиля не так сильно: spearmanr(art, ofi) = 0.69, spearmanr(art, sci) = 0.80. Таким образом, научный и официальный стиль похожи друг на друга больше, чем каждый из них похож на художественный.\n",
    "\n",
    "Можно заметить, что несмотря на фильтрацию стоп-слов, в частотных словарях все равно остались некоторые служебные части речи. Попробуем их отфильтровать и посмотреть, что получится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fd in [POS_freq_art, POS_freq_sci, POS_freq_ofi]:\n",
    "    del fd['PREP'] # удаляем предлоги\n",
    "    del fd['CONJ'] # удаляем союзы\n",
    "    del fd['NPRO'] # удаляем местоимения\n",
    "    del fd['PRCL'] # удаляем частицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частотные словари, образующиеся в итоге:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'ADJF': 3487,\n",
       "          'ADJS': 519,\n",
       "          'ADVB': 2047,\n",
       "          'COMP': 145,\n",
       "          'GRND': 467,\n",
       "          'INFN': 1000,\n",
       "          'INTJ': 71,\n",
       "          'NOUN': 8535,\n",
       "          'NUMR': 259,\n",
       "          'PRED': 34,\n",
       "          'PRTF': 302,\n",
       "          'PRTS': 254,\n",
       "          'VERB': 5072})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_freq_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'ADJF': 932,\n",
       "          'ADJS': 35,\n",
       "          'ADVB': 71,\n",
       "          'COMP': 2,\n",
       "          'GRND': 24,\n",
       "          'INFN': 132,\n",
       "          'NOUN': 2759,\n",
       "          'NUMR': 10,\n",
       "          'PRTF': 147,\n",
       "          'PRTS': 50,\n",
       "          'VERB': 379})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_freq_sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'ADJF': 5672,\n",
       "          'ADJS': 52,\n",
       "          'ADVB': 239,\n",
       "          'GRND': 14,\n",
       "          'INFN': 272,\n",
       "          'NOUN': 13477,\n",
       "          'NUMR': 60,\n",
       "          'PRED': 32,\n",
       "          'PRTF': 833,\n",
       "          'PRTS': 238,\n",
       "          'VERB': 883})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_freq_ofi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделаем процедуру, аналогичную вышеописанной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = list(POS_freq_sci.keys())\n",
    "b.extend(list(POS_freq_ofi.keys()))\n",
    "b.extend(list(POS_freq_art.keys()))\n",
    "b = set(b)\n",
    "b = list(b)\n",
    "\n",
    "art_no_sw = []\n",
    "sci_no_sw = []\n",
    "ofi_no_sw = []\n",
    "\n",
    "for k in b:\n",
    "    art_no_sw.append(POS_freq_art[k])\n",
    "    sci_no_sw.append(POS_freq_sci[k])\n",
    "    ofi_no_sw.append(POS_freq_ofi[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем новые корреляции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.81155510062407588, pvalue=0.00075652329921874391)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.spearmanr(art_no_sw, ofi_no_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.88858405932737805, pvalue=4.9102393737752382e-05)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.spearmanr(art_no_sw, sci_no_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.95179063360881544, pvalue=5.546738050422406e-07)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts.spearmanr(sci_no_sw, ofi_no_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно наблюдать увеличение коэффициентов корреляции Спирмена во всех трех случаях, однако принципиальные выводы остаются неизменными: гипотеза о равенстве корреляции 0 отвергается в пользу альтернативной (о неравенстве), тексты научного и официального стиля более близки друг к другу, нежели к художественному тексту."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('хреноoevsky.txt')\n",
    "text = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в\n",
      "начале\n",
      "июля\n",
      "в\n",
      "чрезвычайно\n",
      "жаркое\n",
      "время\n",
      "под\n",
      "вечер\n",
      "один\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from string import punctuation\n",
    "exclude = set(punctuation + '0123456789\\n'+u'–—'+u'«»')\n",
    "merged_text = ''.join(ch for ch in text if ch not in exclude)\n",
    "tokens = WhitespaceTokenizer().tokenize(merged_text.lower())\n",
    "for i in tokens[:10]: print(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of tokens:  42126\n",
      "N of types: 10359\n",
      "<FreqDist with 10359 samples and 42126 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print('N of tokens: ', len(tokens))\n",
    "types = nltk.FreqDist(tokens)\n",
    "print('N of types:', len(types))\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в\n",
      "начало\n",
      "июль\n",
      "в\n",
      "чрезвычайно\n",
      "жаркое\n",
      "время\n",
      "под\n",
      "вечер\n",
      "один\n",
      "молодая\n",
      "человек\n",
      "выйти\n",
      "из\n",
      "свой\n",
      "каморка\n",
      "который\n",
      "нанимать\n",
      "от\n",
      "жильцов\n"
     ]
    }
   ],
   "source": [
    "for word in tokens[:20]:\n",
    "    print(morph.parse(word)[0].normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of lemmata: 6023\n",
      "и 2367\n",
      "он 1535\n",
      "в 1077\n",
      "не 861\n",
      "что 764\n",
      "на 663\n",
      "быть 647\n",
      "с 599\n",
      "весь 551\n",
      "я 519\n",
      "а 446\n",
      "как 419\n",
      "она 380\n",
      "это 373\n",
      "но 352\n",
      "же 268\n",
      "ты 259\n",
      "к 253\n",
      "так 241\n",
      "тот 228\n"
     ]
    }
   ],
   "source": [
    "# это не нужно\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "lemmata = nltk.FreqDist()\n",
    "for t in types:\n",
    "    try:\n",
    "        l = morph.parse(t)[0].normal_form\n",
    "        if l in lemmata:\n",
    "            lemmata[l] += types[t]\n",
    "        else:\n",
    "            lemmata[l] = types[t]\n",
    "    except IndexError:\n",
    "        if t in lemmata:\n",
    "            lemmata[t] += types[t]\n",
    "        else:\n",
    "            lemmata[t] = types[t]\n",
    "print('N of lemmata:', len(lemmata))\n",
    "for i in lemmata.most_common(20):\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "mystopwords = stopwords.words('russian')+[u'это', u'иза', u'свой',u'млрд', u'млн',u'млна',u'тыс',u'трлн']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "весь 551\n",
      "ещё 176\n",
      "мочь 163\n",
      "стать 126\n",
      "человек 123\n",
      "который 116\n",
      "рука 111\n",
      "самый 105\n",
      "очень 103\n",
      "дело 98\n",
      "раскольник 97\n",
      "знать 83\n",
      "сказать 79\n",
      "говорить 79\n",
      "хотеть 77\n",
      "минута 76\n",
      "пойти 73\n",
      "дверь 73\n",
      "время 67\n",
      "дом 65\n"
     ]
    }
   ],
   "source": [
    "lemmata_no_sw = nltk.FreqDist()\n",
    "for l in lemmata:\n",
    "    if not l in mystopwords:\n",
    "        lemmata_no_sw[l] = lemmata[l]\n",
    "for i in lemmata_no_sw.most_common(20):\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
